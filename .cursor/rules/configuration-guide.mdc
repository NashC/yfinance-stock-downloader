---
description: 
globs: 
alwaysApply: true
---
# Configuration Guide

## Configuration Overview
The system now supports **multiple configuration methods** for maximum flexibility:

1. **Auto-Discovery** - Automatically detect CSV files (default)
2. **JSON Configuration** - Flexible configuration files
3. **Legacy Mode** - Backward compatible with original hardcoded sources
4. **Command-line Overrides** - Quick adjustments without config changes

## Auto-Discovery Mode (Recommended)

### Basic Usage
```bash
# Auto-discover CSV files in data/ directory
.venv/bin/python main.py

# Use custom directories
.venv/bin/python main.py --data-dir my_data --output-dir my_output
```

### How Auto-Discovery Works
- **Scans directory** for CSV files (default: `data/`)
- **Detects ticker columns** by looking for common names:
  - `ticker`, `Ticker`, `TICKER`
  - `symbol`, `Symbol`, `SYMBOL`
- **Creates configurations** automatically for each valid CSV
- **Generates output directories** based on file names

### Example Auto-Discovery Output
```
üîç Auto-discovering CSV files in 'data' directory...
‚úì Auto-discovered: etf_list.csv (ticker column: Symbol)
‚úì Auto-discovered: IWB_holdings_250529.csv (ticker column: Ticker)

‚úì Found 2 data source(s):
  ‚Ä¢ Auto-discovered: etf_list.csv
    File: data/etf_list.csv
    Ticker column: Symbol
    Output: output/etf_list_data
```

## JSON Configuration Mode

### Creating Configuration Files
```bash
# Create sample configuration file
.venv/bin/python main.py --create-config

# Use custom configuration
.venv/bin/python main.py --config config.json
```

### Sample JSON Configuration
```json
{
  "start_date": "2000-01-01",
  "end_date": null,
  "processing_mode": "all",
  "specific_sources": [],
  "chunk_size": 25,
  "sleep_between_chunks": 5,
  "individual_sleep": 2,
  "max_retries": 3,
  "initial_backoff": 2,
  "min_data_points": 10,
  "log_file": "stock_download.log",
  "data_sources": {
    "sp500": {
      "file": "data/sp500_tickers.csv",
      "ticker_column": "Symbol",
      "description": "S&P 500 Companies",
      "output_dir": "output/sp500_data",
      "enabled": true,
      "filter_column": "Market Cap",
      "filter_values": ["Large Cap"]
    },
    "etfs": {
      "file": "data/etf_list.csv",
      "ticker_column": "Symbol",
      "description": "ETF Universe",
      "output_dir": "output/etf_data",
      "enabled": true
    }
  }
}
```

### Data Source Configuration Options
Each data source supports:
- **`name`** - Unique identifier for the source
- **`file`** - Path to CSV file
- **`ticker_column`** - Column name containing ticker symbols
- **`description`** - Human-readable description
- **`output_dir`** - Directory for output CSV files
- **`enabled`** - Whether to process this source
- **`filter_column`** (optional) - Column to filter on
- **`filter_values`** (optional) - Values to include in filter

## Legacy Mode (Backward Compatible)

### Usage
```bash
# Use original hardcoded configuration
.venv/bin/python main.py --legacy
```

### Legacy Configuration
Maintains exact same behavior as original version:
- **IWB Holdings** ‚Üí `stock_data/` directory
- **ETF List** ‚Üí `etf_data/` directory
- Same processing logic and output structure

## Processing Modes

### Available Modes
- **`all`** - Process all available/enabled sources (default)
- **`specific`** - Process only named sources
- **`auto`** - Auto-detect and process available files

### Command-line Source Selection
```bash
# Process only specific sources
.venv/bin/python main.py --sources etf_list,iwb_holdings

# Process single source
.venv/bin/python main.py --sources etf_list

# Combine with other options
.venv/bin/python main.py --sources etf_list --chunk-size 10 --sleep 2
```

## Performance Configuration

### Rate Limiting Settings
- **`chunk_size`** - Number of tickers per batch (default: 25)
- **`sleep_between_chunks`** - Seconds between chunks (default: 5)
- **`individual_sleep`** - Seconds between individual downloads (default: 2)
- **`max_retries`** - Maximum retry attempts (default: 3)
- **`initial_backoff`** - Initial backoff time in seconds (default: 2)

### Command-line Performance Overrides
```bash
# Faster processing (higher API usage)
.venv/bin/python main.py --chunk-size 50 --sleep 2

# Conservative processing (lower API usage)
.venv/bin/python main.py --chunk-size 10 --sleep 10
```

## Data Validation Configuration

### Validation Settings
- **`min_data_points`** - Minimum data points to consider valid (default: 10)
- **Ticker validation** - Automatic validation using regex patterns
- **Data quality checks** - OHLCV column validation and cleaning

### Supported CSV Formats
The system automatically handles CSV files with:
- **Any ticker column name** (auto-detected or specified)
- **Any number of additional columns** (ignored)
- **Various encodings** and formats
- **Header rows** (required)

## Environment Setup

### Modern Setup with uv (Recommended)
```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create and activate virtual environment
uv venv
source .venv/bin/activate

# Install project with all dependencies
uv pip install -e .
```

### Alternative Installation Methods
```bash
# Install dependencies only
uv pip install -r requirements.txt

# Use lock file for exact reproducibility
uv pip sync requirements.lock

# Install with development tools
uv pip install -e ".[dev]"
```

## Adding New Data Sources

### Method 1: Auto-Discovery (Easiest)
1. **Add CSV file** to `data/` directory
2. **Ensure ticker column** has recognizable name
3. **Run auto-discovery**: `.venv/bin/python main.py`

### Method 2: JSON Configuration
1. **Create/edit** configuration file
2. **Add new data source** to `data_sources` section
3. **Specify all required fields**
4. **Run with config**: `.venv/bin/python main.py --config config.json`

### Example: Adding Custom Stock List
```json
{
  "data_sources": {
    "my_stocks": {
      "file": "data/my_custom_stocks.csv",
      "ticker_column": "Ticker",
      "description": "My Custom Stock List",
      "output_dir": "output/my_stocks_data",
      "enabled": true,
      "filter_column": "Sector",
      "filter_values": ["Technology", "Healthcare"]
    }
  }
}
```

## Configuration Validation

### Automatic Validation
The system automatically validates:
- **File existence** - Checks if CSV files exist
- **Column existence** - Verifies ticker columns are present
- **Ticker validity** - Validates ticker symbol formats
- **Output permissions** - Ensures write access to output directories

### Error Handling
- **Missing files** - Warns and skips missing data sources
- **Invalid columns** - Reports available columns and skips source
- **Permission errors** - Reports directory access issues
- **Configuration errors** - Detailed error messages with suggestions

## Migration from Original Version

### Automatic Migration
The system is **100% backward compatible**:
```bash
# Original behavior (still works exactly the same)
.venv/bin/python main.py --legacy
```

### Recommended Upgrade Path
1. **Test auto-discovery**: `.venv/bin/python main.py`
2. **Create custom config**: `.venv/bin/python main.py --create-config`
3. **Customize as needed**: Edit `config.json` for your requirements
4. **Use new features**: Selective processing, custom sources, filtering
